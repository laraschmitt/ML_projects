{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gridsearch\n",
    "Optimize the hyperparameters of your model with execute a Grid SearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all scores      :\n",
      "{'mean_fit_time': array([0.00452261, 0.0020371 , 0.00200615, 0.00247025, 0.00149164,\n",
      "       0.00366054, 0.00167799, 0.00403976]),\n",
      " 'mean_score_time': array([0.00044794, 0.00051017, 0.00036702, 0.00060301, 0.00039539,\n",
      "       0.00080218, 0.00044465, 0.00084577]),\n",
      " 'mean_test_score': array([0.88051545, 0.89632045, 0.87876106, 0.8963515 , 0.88051545,\n",
      "       0.70131967, 0.86821922, 0.6274181 ]),\n",
      " 'param_C': masked_array(data=[1.0, 1.0, 0.1, 0.1, 0.01, 0.01, 0.001, 0.001],\n",
      "             mask=[False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object),\n",
      " 'param_kernel': masked_array(data=['linear', 'rbf', 'linear', 'rbf', 'linear', 'rbf',\n",
      "                   'linear', 'rbf'],\n",
      "             mask=[False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object),\n",
      " 'params': [{'C': 1.0, 'kernel': 'linear'},\n",
      "            {'C': 1.0, 'kernel': 'rbf'},\n",
      "            {'C': 0.1, 'kernel': 'linear'},\n",
      "            {'C': 0.1, 'kernel': 'rbf'},\n",
      "            {'C': 0.01, 'kernel': 'linear'},\n",
      "            {'C': 0.01, 'kernel': 'rbf'},\n",
      "            {'C': 0.001, 'kernel': 'linear'},\n",
      "            {'C': 0.001, 'kernel': 'rbf'}],\n",
      " 'rank_test_score': array([3, 2, 5, 1, 3, 7, 6, 8], dtype=int32),\n",
      " 'split0_test_score': array([0.84210526, 0.85087719, 0.84210526, 0.81578947, 0.84210526,\n",
      "       0.6754386 , 0.8245614 , 0.62280702]),\n",
      " 'split1_test_score': array([0.86842105, 0.87719298, 0.86842105, 0.90350877, 0.87719298,\n",
      "       0.68421053, 0.83333333, 0.62280702]),\n",
      " 'split2_test_score': array([0.88596491, 0.9122807 , 0.87719298, 0.90350877, 0.87719298,\n",
      "       0.68421053, 0.89473684, 0.63157895]),\n",
      " 'split3_test_score': array([0.9122807 , 0.93859649, 0.9122807 , 0.93859649, 0.9122807 ,\n",
      "       0.71052632, 0.90350877, 0.63157895]),\n",
      " 'split4_test_score': array([0.89380531, 0.90265487, 0.89380531, 0.92035398, 0.89380531,\n",
      "       0.75221239, 0.88495575, 0.62831858]),\n",
      " 'std_fit_time': array([5.90504390e-04, 1.78722129e-04, 1.26680710e-04, 5.73195156e-05,\n",
      "       9.08815347e-05, 8.11141353e-05, 8.78118640e-05, 2.43790336e-04]),\n",
      " 'std_score_time': array([8.70293001e-05, 3.66127109e-05, 2.09808350e-06, 1.74892013e-05,\n",
      "       1.48835841e-05, 2.79916003e-06, 2.16947807e-06, 5.89040784e-05]),\n",
      " 'std_test_score': array([0.02382001, 0.03004353, 0.02367665, 0.04231655, 0.02316494,\n",
      "       0.02803607, 0.03271598, 0.00394868])}\n",
      "\n",
      "best score      : 0.8963514982145628\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from pprint import pprint\n",
    "\n",
    "bca = datasets.load_breast_cancer()\n",
    "\n",
    "X = bca.data[:,:2]  # only two features\n",
    "y = bca.target\n",
    "\n",
    "svc = svm.SVC()\n",
    "\n",
    "grid = GridSearchCV(svc,\n",
    "        param_grid={'C': [1.0, 0.1, 0.01, 0.001], 'kernel':['linear', 'rbf']},\n",
    "        scoring='accuracy',\n",
    "        n_jobs=1,\n",
    "        cv=None\n",
    "        )\n",
    "\n",
    "grid.fit(X, y)\n",
    "print(\"all scores      :\")\n",
    "pprint(grid.cv_results_)\n",
    "\n",
    "print(\"\\nbest score      :\", grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.88051545, 0.89632045, 0.87876106, 0.8963515 , 0.88051545,\n",
       "       0.70131967, 0.86821922, 0.6274181 ])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_mean_test_score = grid.cv_results_['mean_test_score']\n",
    "grid_mean_test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'C': 1.0, 'kernel': 'linear'},\n",
       " {'C': 1.0, 'kernel': 'rbf'},\n",
       " {'C': 0.1, 'kernel': 'linear'},\n",
       " {'C': 0.1, 'kernel': 'rbf'},\n",
       " {'C': 0.01, 'kernel': 'linear'},\n",
       " {'C': 0.01, 'kernel': 'rbf'},\n",
       " {'C': 0.001, 'kernel': 'linear'},\n",
       " {'C': 0.001, 'kernel': 'rbf'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_params = grid.cv_results_['params']\n",
    "grid_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-1a5961eb274f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m pivot = pd.pivot_table(df, values='mean_test_score', index=['kernel'],\n\u001b[0;32m---> 12\u001b[0;31m                      columns=['C'], aggfunc=np.sum)\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mpivot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame.from_dict(grid_params)\n",
    "df['mean_test_score'] = grid_mean_test_score\n",
    "##df[\"grid_params\"] = df[\"C\"].astype(str) + ' ' + df[\"kernel\"]\n",
    "##df = df.drop(columns=['C', 'kernel'])\n",
    "##df.shape\n",
    "df\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "pivot = pd.pivot_table(df, values='mean_test_score', index=['kernel'],\n",
    "                     columns=['C'], aggfunc=np.sum)\n",
    "pivot\n",
    "\n",
    "sns.heatmap(pivot, cmap=\"Greens\") # plus any other aesthetic parameters you wish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline\n",
    "\n",
    "\n",
    "Construct a pipeline that includes the feature engineering and your model, so that you can create predictions on new data without retraining.\n",
    "\n",
    "Optimize the feature engineering part by hyperparameter search. For that, the parameter dictionary in GridSearchCV requires the hyperparameters to be specified in the format modelname__hyperparametername.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
