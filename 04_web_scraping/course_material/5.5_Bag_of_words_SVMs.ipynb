{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Words\n",
    "### A preprocessing method for language representation\n",
    "\n",
    "Bag of WOrds is a method that converts a text corpus into a numerical matrix, so that Machine Learning methods can use it as training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| <p style=\"font-size: 15px\">Concept</p>      | <p style=\"font-size: 15px\">Description</p> \n",
    "| ----------- | ----------- |\n",
    "| <p style=\"font-size: 15px\">Corpus</p>      | <p style=\"font-size: 15px\">a list of strings (text documents)</p>       |\n",
    "| <p style=\"font-size: 15px\">Tokenization</p>      | <p style=\"font-size: 15px\">dividing a text into words (or other units)</p>       \n",
    "| <p style=\"font-size: 15px\">Vectorization</p>      | <p style=\"font-size: 15px\">converting text into numbers</p>\n",
    "| <p style=\"font-size: 15px\">Stop words</p>      | <p style=\"font-size: 15px\">frequent words that carry little meaning</p>      \n",
    "| <p style=\"font-size: 15px\">Stemming</p>      | <p style=\"font-size: 15px\">cutting off word endings</p>      \n",
    "| <p style=\"font-size: 15px\">n-grams</p>      | <p style=\"font-size: 15px\">tokenizing into strings with n words</p>  \n",
    "| <p style=\"font-size: 15px\">TF-IDF</p>      | <p style=\"font-size: 15px\">method for normalizing counts</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Objectives:\n",
    "* Why do we need to preprocess language for Machine Learning?\n",
    "* What is a CountVector \n",
    "* What is a TFIDF-Vector\n",
    "* How do we apply this to the week's task?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First off - we need a corpus!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "coldplay = \"\"\"Drink from me, drink from me (oh-ah-oh-ah)\n",
    "Then we'll shoot across the (symphony)\n",
    "Then we'll shoot across the sky\n",
    "Drink from me, drink from me (oh-ah-oh-ah)\n",
    "Then we'll shoot across the (oh-ah-oh-ah)\n",
    "Symphony\n",
    "(So high, so high)\n",
    "Then we'll shoot across the sky\n",
    "Oh, angels sent from up above\n",
    "You know you make my world light up\n",
    "When I was down, when I was hurt\n",
    "You came to lift me up\n",
    "Life is a drink, and love's a drug\n",
    "Oh now I think I must be miles up\n",
    "When I was hurt, withered, dried up\n",
    "You came to rain a flood\n",
    "So drink from me, drink from me\n",
    "When I was so thirsty\n",
    "We're on a symphony\n",
    "Now I just can't get enough\n",
    "Put your wings on me, wings on me\n",
    "When I was so heavy\n",
    "We're on a symphony\n",
    "When I'm lower, lower, lower, low\n",
    "Ah-oh-ah-oh-ah\n",
    "Got me feeling drunk and high\n",
    "So high, so high\n",
    "Oh-ah-oh-ah-oh-ah\n",
    "I'm feeling drunk and high\n",
    "So high, so high\n",
    "(Woo)\n",
    "(Woo-ooo-ooo-woo)\n",
    "Oh, angels sent from up above\n",
    "I feel it coursing through my blood\n",
    "Life is a drink, your love's about\n",
    "To make the stars come out\n",
    "Put your wings on me, wings on me\n",
    "When I was so heavy\n",
    "We're on a symphony\n",
    "When I'm lower, lower, lower, low\n",
    "Ah-oh-ah-oh-ah\n",
    "Got me feeling drunk and high\n",
    "So high, so high\n",
    "Oh-ah-oh-ah-oh-ah\n",
    "I'm feeling drunk and high\n",
    "So high, so high\n",
    "Ah-oh-ah-oh-ah\n",
    "La, la, la, la, la, la, la\n",
    "So high, so high\n",
    "Ah-oh-ah-oh-ah\n",
    "I'm feeling drunk and high\n",
    "So high, so high\n",
    "Then we'll shoot across the sky\n",
    "Then we'll shoot across the\n",
    "Then we'll shoot across the sky\n",
    "Then we'll shoot across the (then we'll shoot)\n",
    "Then we'll shoot across the sky\n",
    "Then we'll shoot across the\n",
    "Then we'll shoot across the sky\n",
    "Then we'll shoot across the\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "masego = \"\"\"Big white house with the chains in the mirror\n",
    "Fender guitars and they hang in the air\n",
    "Ladies are large, they look amazing in here\n",
    "It's her birthday, got her panties in the air\n",
    "Hit up the broad with the bangs in her hair\n",
    "Hit up the mob and the gang and the men\n",
    "Quit your job, there's a change in the air\n",
    "Call me MJ, with the man in the mirror\n",
    "\n",
    "Face down, laid up\n",
    "Bust down, cake up\n",
    "Ladies, get your weight up\n",
    "Welcome to the cake club\n",
    "Face down, laid up\n",
    "Bust down, cake up\n",
    "Ladies, get your weight up\n",
    "Welcome to the cake club\n",
    "\n",
    "Jiggle it, hit the room\n",
    "Partna, pon it's way\n",
    "Jiggle it, hit the room\n",
    "Show time finally\n",
    "\n",
    "Bring that back, you put your hands in the air\n",
    "Just like that, yeah, you're famous in here\n",
    "Do that that and make it rain over here\n",
    "Happy birthday, it's some quakin' over here (yeah)\n",
    "It's getting wild over here (yeah)\n",
    "It's getting loud over here (yeah)\n",
    "A big crowd over here\n",
    "Get the first aid 'cause you're killing over here\n",
    "\n",
    "Face down, laid up\n",
    "Bust down, cake up\n",
    "Ladies, get your weight up\n",
    "Welcome to the cake club\n",
    "Face down, laid up\n",
    "Bust down, cake up\n",
    "Ladies, get your weight up\n",
    "Welcome to the cake club\n",
    "\n",
    "Jiggle it, hit the room\n",
    "Partna, pon it's way\n",
    "Jiggle it, hit the room\n",
    "Show time finally\n",
    "\n",
    "Yeah (ahh)\n",
    "Yeah (yeah)\n",
    "Finally, finally\n",
    "Yeah (finally, hee, hee, hee)\n",
    "Listen\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs = []\n",
    "songs.append(coldplay)\n",
    "songs.append(masego)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_labels = ['coldplay', 'masego']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = songs\n",
    "y = artist_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why do we need to preprocess language?\n",
    "* In short- nothing works if you don't!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def why_transform(X,y):\n",
    "    m = LogisticRegression()\n",
    "    try:\n",
    "        m.fit(X, y)\n",
    "    except(ValueError):\n",
    "        print('We have a Value error!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have a Value error!\n"
     ]
    }
   ],
   "source": [
    "why_transform(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of Words:\n",
    "* The first attempt at creating word vectors. \n",
    "* The common approach for word vectorisation until 2013 (Mikolov et al)\n",
    "* (These days we use Sesame Street characters (BERT, ELMO))\n",
    "* Two types of BOW - Count Vectors and TF-IDF Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is a Count Vectorizer?:\n",
    "* A word-counter for every word in a given document\n",
    "\n",
    "#### Steps to build\n",
    "* Create a corpus\n",
    "* Fit a CV on it\n",
    "* Transform the corpus into a sparse, then dense, matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer() #stop_words='english'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ngram_range = if not 1, then we do not only consider words but also a pair of words, e.g. New York"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b' captures all alphanumerics, captures all alphanumeric patterns with 2 or more than 2 letters (that means that \"I\" or \"a\" will not be included\n",
    "\n",
    "the whitespaces in English and German seperate the words for us, does not work e.g. with Chinese"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### overwrite the token_pattern to your costum one!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'drink': 34,\n",
       " 'from': 46,\n",
       " 'me': 89,\n",
       " 'oh': 98,\n",
       " 'ah': 3,\n",
       " 'then': 122,\n",
       " 'we': 133,\n",
       " 'll': 81,\n",
       " 'shoot': 113,\n",
       " 'across': 2,\n",
       " 'the': 121,\n",
       " 'symphony': 119,\n",
       " 'sky': 115,\n",
       " 'so': 116,\n",
       " 'high': 60,\n",
       " 'angels': 9,\n",
       " 'sent': 112,\n",
       " 'up': 130,\n",
       " 'above': 1,\n",
       " 'you': 145,\n",
       " 'know': 71,\n",
       " 'make': 87,\n",
       " 'my': 96,\n",
       " 'world': 143,\n",
       " 'light': 78,\n",
       " 'when': 136,\n",
       " 'was': 131,\n",
       " 'down': 32,\n",
       " 'hurt': 63,\n",
       " 'came': 22,\n",
       " 'to': 129,\n",
       " 'lift': 77,\n",
       " 'life': 76,\n",
       " 'is': 65,\n",
       " 'and': 8,\n",
       " 'love': 84,\n",
       " 'drug': 35,\n",
       " 'now': 97,\n",
       " 'think': 125,\n",
       " 'must': 95,\n",
       " 'be': 13,\n",
       " 'miles': 91,\n",
       " 'withered': 141,\n",
       " 'dried': 33,\n",
       " 'rain': 109,\n",
       " 'flood': 45,\n",
       " 'thirsty': 126,\n",
       " 're': 110,\n",
       " 'on': 99,\n",
       " 'just': 69,\n",
       " 'can': 23,\n",
       " 'get': 48,\n",
       " 'enough': 37,\n",
       " 'put': 106,\n",
       " 'your': 146,\n",
       " 'wings': 139,\n",
       " 'heavy': 56,\n",
       " 'lower': 86,\n",
       " 'low': 85,\n",
       " 'got': 50,\n",
       " 'feeling': 41,\n",
       " 'drunk': 36,\n",
       " 'woo': 142,\n",
       " 'ooo': 100,\n",
       " 'feel': 40,\n",
       " 'it': 66,\n",
       " 'coursing': 29,\n",
       " 'through': 127,\n",
       " 'blood': 16,\n",
       " 'about': 0,\n",
       " 'stars': 118,\n",
       " 'come': 28,\n",
       " 'out': 101,\n",
       " 'la': 72,\n",
       " 'big': 14,\n",
       " 'white': 137,\n",
       " 'house': 62,\n",
       " 'with': 140,\n",
       " 'chains': 25,\n",
       " 'in': 64,\n",
       " 'mirror': 92,\n",
       " 'fender': 42,\n",
       " 'guitars': 51,\n",
       " 'they': 124,\n",
       " 'hang': 54,\n",
       " 'air': 6,\n",
       " 'ladies': 73,\n",
       " 'are': 10,\n",
       " 'large': 75,\n",
       " 'look': 82,\n",
       " 'amazing': 7,\n",
       " 'here': 59,\n",
       " 'her': 58,\n",
       " 'birthday': 15,\n",
       " 'panties': 103,\n",
       " 'hit': 61,\n",
       " 'broad': 18,\n",
       " 'bangs': 12,\n",
       " 'hair': 52,\n",
       " 'mob': 94,\n",
       " 'gang': 47,\n",
       " 'men': 90,\n",
       " 'quit': 108,\n",
       " 'job': 68,\n",
       " 'there': 123,\n",
       " 'change': 26,\n",
       " 'call': 21,\n",
       " 'mj': 93,\n",
       " 'man': 88,\n",
       " 'face': 38,\n",
       " 'laid': 74,\n",
       " 'bust': 19,\n",
       " 'cake': 20,\n",
       " 'weight': 134,\n",
       " 'welcome': 135,\n",
       " 'club': 27,\n",
       " 'jiggle': 67,\n",
       " 'room': 111,\n",
       " 'partna': 104,\n",
       " 'pon': 105,\n",
       " 'way': 132,\n",
       " 'show': 114,\n",
       " 'time': 128,\n",
       " 'finally': 43,\n",
       " 'bring': 17,\n",
       " 'that': 120,\n",
       " 'back': 11,\n",
       " 'hands': 53,\n",
       " 'like': 79,\n",
       " 'yeah': 144,\n",
       " 'famous': 39,\n",
       " 'do': 31,\n",
       " 'over': 102,\n",
       " 'happy': 55,\n",
       " 'some': 117,\n",
       " 'quakin': 107,\n",
       " 'getting': 49,\n",
       " 'wild': 138,\n",
       " 'loud': 83,\n",
       " 'crowd': 30,\n",
       " 'first': 44,\n",
       " 'aid': 5,\n",
       " 'cause': 24,\n",
       " 'killing': 70,\n",
       " 'ahh': 4,\n",
       " 'hee': 57,\n",
       " 'listen': 80}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_corpus = cv.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2x147 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 163 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sparse Matrix vs Dense Matrix\n",
    "Most of our matrix consists of zeroes. A Sparse Matrix only stores the non-zero values to save memory. We need to convert it into a **dense** matrix to view it effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Drink from me, drink from me (oh-ah-oh-ah)\\nThen we'll shoot across the (symphony)\\nThen we'll shoot across the sky\\nDrink from me, drink from me (oh-ah-oh-ah)\\nThen we'll shoot across the (oh-ah-oh-ah)\\nSymphony\\n(So high, so high)\\nThen we'll shoot across the sky\\nOh, angels sent from up above\\nYou know you make my world light up\\nWhen I was down, when I was hurt\\nYou came to lift me up\\nLife is a drink, and love's a drug\\nOh now I think I must be miles up\\nWhen I was hurt, withered, dried up\\nYou came to rain a flood\\nSo drink from me, drink from me\\nWhen I was so thirsty\\nWe're on a symphony\\nNow I just can't get enough\\nPut your wings on me, wings on me\\nWhen I was so heavy\\nWe're on a symphony\\nWhen I'm lower, lower, lower, low\\nAh-oh-ah-oh-ah\\nGot me feeling drunk and high\\nSo high, so high\\nOh-ah-oh-ah-oh-ah\\nI'm feeling drunk and high\\nSo high, so high\\n(Woo)\\n(Woo-ooo-ooo-woo)\\nOh, angels sent from up above\\nI feel it coursing through my blood\\nLife is a drink, your love's about\\nTo make the stars come out\\nPut your wings on me, wings on me\\nWhen I was so heavy\\nWe're on a symphony\\nWhen I'm lower, lower, lower, low\\nAh-oh-ah-oh-ah\\nGot me feeling drunk and high\\nSo high, so high\\nOh-ah-oh-ah-oh-ah\\nI'm feeling drunk and high\\nSo high, so high\\nAh-oh-ah-oh-ah\\nLa, la, la, la, la, la, la\\nSo high, so high\\nAh-oh-ah-oh-ah\\nI'm feeling drunk and high\\nSo high, so high\\nThen we'll shoot across the sky\\nThen we'll shoot across the\\nThen we'll shoot across the sky\\nThen we'll shoot across the (then we'll shoot)\\nThen we'll shoot across the sky\\nThen we'll shoot across the\\nThen we'll shoot across the sky\\nThen we'll shoot across the\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "songs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>about</th>\n",
       "      <th>above</th>\n",
       "      <th>across</th>\n",
       "      <th>ah</th>\n",
       "      <th>ahh</th>\n",
       "      <th>aid</th>\n",
       "      <th>air</th>\n",
       "      <th>amazing</th>\n",
       "      <th>and</th>\n",
       "      <th>angels</th>\n",
       "      <th>...</th>\n",
       "      <th>white</th>\n",
       "      <th>wild</th>\n",
       "      <th>wings</th>\n",
       "      <th>with</th>\n",
       "      <th>withered</th>\n",
       "      <th>woo</th>\n",
       "      <th>world</th>\n",
       "      <th>yeah</th>\n",
       "      <th>you</th>\n",
       "      <th>your</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>coldplay</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>masego</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 147 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          about  above  across  ah  ahh  aid  air  amazing  and  angels  ...  \\\n",
       "coldplay      1      2      12  24    0    0    0        0    6       2  ...   \n",
       "masego        0      0       0   0    1    1    4        1    4       0  ...   \n",
       "\n",
       "          white  wild  wings  with  withered  woo  world  yeah  you  your  \n",
       "coldplay      0     0      4     0         1    3      1     0    4     3  \n",
       "masego        1     1      0     3         0    0      0     8    3     6  \n",
       "\n",
       "[2 rows x 147 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = pd.DataFrame(new_corpus.todense(), columns=cv.get_feature_names(), index=['coldplay', 'masego'])\n",
    "df.head()\n",
    "# first row is the coldplay song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(oh-ah-oh-ah)',\n",
       " '(oh-ah-oh-ah)',\n",
       " '(oh-ah-oh-ah)',\n",
       " '(so',\n",
       " '(symphony)',\n",
       " '(then',\n",
       " '(woo)',\n",
       " '(woo-ooo-ooo-woo)',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'above',\n",
       " 'across',\n",
       " 'across',\n",
       " 'across',\n",
       " 'across',\n",
       " 'across',\n",
       " 'across',\n",
       " 'across',\n",
       " 'across',\n",
       " 'across',\n",
       " 'across',\n",
       " 'across',\n",
       " 'across',\n",
       " 'ah-oh-ah-oh-ah',\n",
       " 'ah-oh-ah-oh-ah',\n",
       " 'ah-oh-ah-oh-ah',\n",
       " 'ah-oh-ah-oh-ah',\n",
       " 'and',\n",
       " 'and',\n",
       " 'and',\n",
       " 'and',\n",
       " 'and',\n",
       " 'and',\n",
       " 'angels',\n",
       " 'angels',\n",
       " 'be',\n",
       " 'blood',\n",
       " 'came',\n",
       " 'came',\n",
       " \"can't\",\n",
       " 'come',\n",
       " 'coursing',\n",
       " 'down,',\n",
       " 'dried',\n",
       " 'drink',\n",
       " 'drink',\n",
       " 'drink',\n",
       " 'drink',\n",
       " 'drink',\n",
       " 'drink',\n",
       " 'drink,',\n",
       " 'drink,',\n",
       " 'drug',\n",
       " 'drunk',\n",
       " 'drunk',\n",
       " 'drunk',\n",
       " 'drunk',\n",
       " 'drunk',\n",
       " 'enough',\n",
       " 'feel',\n",
       " 'feeling',\n",
       " 'feeling',\n",
       " 'feeling',\n",
       " 'feeling',\n",
       " 'feeling',\n",
       " 'flood',\n",
       " 'from',\n",
       " 'from',\n",
       " 'from',\n",
       " 'from',\n",
       " 'from',\n",
       " 'from',\n",
       " 'from',\n",
       " 'from',\n",
       " 'get',\n",
       " 'got',\n",
       " 'got',\n",
       " 'heavy',\n",
       " 'heavy',\n",
       " 'high',\n",
       " 'high',\n",
       " 'high',\n",
       " 'high',\n",
       " 'high',\n",
       " 'high',\n",
       " 'high',\n",
       " 'high',\n",
       " 'high',\n",
       " 'high',\n",
       " 'high',\n",
       " 'high)',\n",
       " 'high,',\n",
       " 'high,',\n",
       " 'high,',\n",
       " 'high,',\n",
       " 'high,',\n",
       " 'high,',\n",
       " 'high,',\n",
       " 'hurt',\n",
       " 'hurt,',\n",
       " 'i',\n",
       " 'i',\n",
       " 'i',\n",
       " 'i',\n",
       " 'i',\n",
       " 'i',\n",
       " 'i',\n",
       " 'i',\n",
       " 'i',\n",
       " 'i',\n",
       " \"i'm\",\n",
       " \"i'm\",\n",
       " \"i'm\",\n",
       " \"i'm\",\n",
       " \"i'm\",\n",
       " 'is',\n",
       " 'is',\n",
       " 'it',\n",
       " 'just',\n",
       " 'know',\n",
       " 'la',\n",
       " 'la,',\n",
       " 'la,',\n",
       " 'la,',\n",
       " 'la,',\n",
       " 'la,',\n",
       " 'la,',\n",
       " 'life',\n",
       " 'life',\n",
       " 'lift',\n",
       " 'light',\n",
       " \"love's\",\n",
       " \"love's\",\n",
       " 'low',\n",
       " 'low',\n",
       " 'lower,',\n",
       " 'lower,',\n",
       " 'lower,',\n",
       " 'lower,',\n",
       " 'lower,',\n",
       " 'lower,',\n",
       " 'make',\n",
       " 'make',\n",
       " 'me',\n",
       " 'me',\n",
       " 'me',\n",
       " 'me',\n",
       " 'me',\n",
       " 'me',\n",
       " 'me',\n",
       " 'me',\n",
       " 'me,',\n",
       " 'me,',\n",
       " 'me,',\n",
       " 'me,',\n",
       " 'me,',\n",
       " 'miles',\n",
       " 'must',\n",
       " 'my',\n",
       " 'my',\n",
       " 'now',\n",
       " 'now',\n",
       " 'oh',\n",
       " 'oh,',\n",
       " 'oh,',\n",
       " 'oh-ah-oh-ah-oh-ah',\n",
       " 'oh-ah-oh-ah-oh-ah',\n",
       " 'on',\n",
       " 'on',\n",
       " 'on',\n",
       " 'on',\n",
       " 'on',\n",
       " 'on',\n",
       " 'on',\n",
       " 'out',\n",
       " 'put',\n",
       " 'put',\n",
       " 'rain',\n",
       " 'sent',\n",
       " 'sent',\n",
       " 'shoot',\n",
       " 'shoot',\n",
       " 'shoot',\n",
       " 'shoot',\n",
       " 'shoot',\n",
       " 'shoot',\n",
       " 'shoot',\n",
       " 'shoot',\n",
       " 'shoot',\n",
       " 'shoot',\n",
       " 'shoot',\n",
       " 'shoot',\n",
       " 'shoot)',\n",
       " 'sky',\n",
       " 'sky',\n",
       " 'sky',\n",
       " 'sky',\n",
       " 'sky',\n",
       " 'sky',\n",
       " 'so',\n",
       " 'so',\n",
       " 'so',\n",
       " 'so',\n",
       " 'so',\n",
       " 'so',\n",
       " 'so',\n",
       " 'so',\n",
       " 'so',\n",
       " 'so',\n",
       " 'so',\n",
       " 'so',\n",
       " 'so',\n",
       " 'so',\n",
       " 'so',\n",
       " 'so',\n",
       " 'so',\n",
       " 'stars',\n",
       " 'symphony',\n",
       " 'symphony',\n",
       " 'symphony',\n",
       " 'symphony',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'the',\n",
       " 'then',\n",
       " 'then',\n",
       " 'then',\n",
       " 'then',\n",
       " 'then',\n",
       " 'then',\n",
       " 'then',\n",
       " 'then',\n",
       " 'then',\n",
       " 'then',\n",
       " 'then',\n",
       " 'then',\n",
       " 'think',\n",
       " 'thirsty',\n",
       " 'through',\n",
       " 'to',\n",
       " 'to',\n",
       " 'to',\n",
       " 'up',\n",
       " 'up',\n",
       " 'up',\n",
       " 'up',\n",
       " 'up',\n",
       " 'up',\n",
       " 'was',\n",
       " 'was',\n",
       " 'was',\n",
       " 'was',\n",
       " 'was',\n",
       " 'was',\n",
       " \"we'll\",\n",
       " \"we'll\",\n",
       " \"we'll\",\n",
       " \"we'll\",\n",
       " \"we'll\",\n",
       " \"we'll\",\n",
       " \"we'll\",\n",
       " \"we'll\",\n",
       " \"we'll\",\n",
       " \"we'll\",\n",
       " \"we'll\",\n",
       " \"we'll\",\n",
       " \"we'll\",\n",
       " \"we're\",\n",
       " \"we're\",\n",
       " \"we're\",\n",
       " 'when',\n",
       " 'when',\n",
       " 'when',\n",
       " 'when',\n",
       " 'when',\n",
       " 'when',\n",
       " 'when',\n",
       " 'when',\n",
       " 'wings',\n",
       " 'wings',\n",
       " 'wings',\n",
       " 'wings',\n",
       " 'withered,',\n",
       " 'world',\n",
       " 'you',\n",
       " 'you',\n",
       " 'you',\n",
       " 'you',\n",
       " 'your',\n",
       " 'your',\n",
       " 'your']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(songs[0].lower().split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cons\n",
    "* word order isn't recognized in BOW\n",
    "* number of columns gets big very quick, especially with n-grams > 1\n",
    "* lack of uniqueness of each term in CV -  <span style=\"background-color:lightblue\">**WE NEED TO NORMALIZE OUR VECTORS IN THE COLUMN AND THE ROW SPACE**</span> \n",
    "    * column space - how much of a 'fingerprint' does a particular word a particular artist\n",
    "    * row space - long songs should have less value assigned to individual words vs short songs\n",
    "\n",
    "\n",
    "### Pros\n",
    "* easy to understand\n",
    "* quick to implement\n",
    "* work surprisingly well for many NLP tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf = just means count vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Tf-Idf Transformer:\n",
    "\n",
    "* TF - Term Frequency (% count of a word w in doc d)\n",
    "* IDF - Inverse Document Frequency\n",
    "\n",
    "$TFIDF = TF(w,d) * IDF(w)$\n",
    "\n",
    "$IDF(w) = log(\\frac{1+ no.documents}{1 + no.documents containing word w})+1$\n",
    "\n",
    "##### The steps for calculating TFIDF are:\n",
    "* For each vector:\n",
    "    * Calculate the term frequency for each term in the vector\n",
    "    * Calculate the inverse doc frequency for each term in the vector\n",
    "    * Multiply the two for each term in the vector\n",
    "* Then normalise each vector by the Euclidean norm (numpy.linalg.norm)\n",
    "    * $norm = \\frac{v}{||v||^2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out the math behind TFIDF:\n",
    "* https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html#sklearn.feature_extraction.text.TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = TfidfTransformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.fit(new_corpus) # not on the original corpus, but on the count vectorizer corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_corpus = tf.transform(new_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>about</th>\n",
       "      <th>above</th>\n",
       "      <th>across</th>\n",
       "      <th>ah</th>\n",
       "      <th>ahh</th>\n",
       "      <th>aid</th>\n",
       "      <th>air</th>\n",
       "      <th>amazing</th>\n",
       "      <th>and</th>\n",
       "      <th>angels</th>\n",
       "      <th>...</th>\n",
       "      <th>white</th>\n",
       "      <th>wild</th>\n",
       "      <th>wings</th>\n",
       "      <th>with</th>\n",
       "      <th>withered</th>\n",
       "      <th>woo</th>\n",
       "      <th>world</th>\n",
       "      <th>yeah</th>\n",
       "      <th>you</th>\n",
       "      <th>your</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>coldplay</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.03</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>masego</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 147 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          about  above  across    ah   ahh   aid   air  amazing   and  angels  \\\n",
       "coldplay   0.02   0.03     0.2  0.41  0.00  0.00  0.00     0.00  0.07    0.03   \n",
       "masego     0.00   0.00     0.0  0.00  0.03  0.03  0.12     0.03  0.08    0.00   \n",
       "\n",
       "          ...  white  wild  wings  with  withered   woo  world  yeah   you  \\\n",
       "coldplay  ...   0.00  0.00   0.07  0.00      0.02  0.05   0.02  0.00  0.05   \n",
       "masego    ...   0.03  0.03   0.00  0.09      0.00  0.00   0.00  0.24  0.06   \n",
       "\n",
       "          your  \n",
       "coldplay  0.04  \n",
       "masego    0.13  \n",
       "\n",
       "[2 rows x 147 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.DataFrame(tf_corpus.todense().round(2), columns=cv.get_feature_names(), index=['coldplay', 'masego'])\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "340"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc['coldplay'].sum() # no normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.459999999999999"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.loc['coldplay'].sum() # it does not sum up to 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What happens with new words??\n",
    "* we do not want to refit our model on new lyrics!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 'jovial' not in cv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_song = ['i am very jovial songwriter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>about</th>\n",
       "      <th>above</th>\n",
       "      <th>across</th>\n",
       "      <th>ah</th>\n",
       "      <th>ahh</th>\n",
       "      <th>aid</th>\n",
       "      <th>air</th>\n",
       "      <th>amazing</th>\n",
       "      <th>and</th>\n",
       "      <th>angels</th>\n",
       "      <th>...</th>\n",
       "      <th>white</th>\n",
       "      <th>wild</th>\n",
       "      <th>wings</th>\n",
       "      <th>with</th>\n",
       "      <th>withered</th>\n",
       "      <th>woo</th>\n",
       "      <th>world</th>\n",
       "      <th>yeah</th>\n",
       "      <th>you</th>\n",
       "      <th>your</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 147 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   about  above  across  ah  ahh  aid  air  amazing  and  angels  ...  white  \\\n",
       "0      0      0       0   0    0    0    0        0    0       0  ...      0   \n",
       "\n",
       "   wild  wings  with  withered  woo  world  yeah  you  your  \n",
       "0     0      0     0         0    0      0     0    0     0  \n",
       "\n",
       "[1 rows x 147 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(cv.transform(new_song).todense(), columns=cv.get_feature_names())\n",
    "# the model just ignores the word \"jovial\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(cv.transform(new_song).todense(), columns=cv.get_feature_names()).sum(axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How do we apply to this week's task?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is this week's task?\n",
    "take a string of lyrics, and the model guesses who is the artist!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering (\"word engineering\")\n",
    "* download and save your corpus\n",
    "* create labels for the corpus\n",
    "* transform your lyrics into BOW document vectors\n",
    "* delete some words - cf curse of dimensionality\n",
    "* How can we decide what words to delete?!\n",
    "    * ML solution - coefficients of the words, correlation matrix\n",
    "    * all feature selection techniques should apply\n",
    "    * domain expertise solution - knowing a bit about language\n",
    "    * remove stop words *(e.g. 'i am very similar to something which is also similar to me and that thing is batman' - important words here: similiar, something, batman (got rid of the stopwords like i, am, to, is)*\n",
    "    * standardize plural / singular differentation - stemming \n",
    "    * more tomorrow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The rest - standard ML pipeline\n",
    "* train test splitting\n",
    "* choose a model - RFC, LR, NB, etc.\n",
    "* train and measure it\n",
    "* cross validating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To make your code shorter, you could use the TfidfVectorizer\n",
    "* This does both steps (count vectorizer and tfidfTransfomer) in one. The reason we show both in the tutorial is because its easier to understand word vectors this way\n",
    "\n",
    "`from sklearn.feature_extraction.text import TfidfVectorizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
